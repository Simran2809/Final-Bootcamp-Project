{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da241d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function to return missing values in a dataframe\n",
    "\n",
    "def Percent_Missing(dataframe):\n",
    "    missing_count = dataframe.isnull().sum()\n",
    "    percent_missing = dataframe.isnull().sum() * 100 / len(dataframe)\n",
    "    missing_value_df = pd.DataFrame({'column_name': dataframe.columns,\n",
    "                                     'missing_count': missing_count,\n",
    "                                     'percent_missing': percent_missing})\n",
    "    print(missing_value_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5b5d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to change datatype of the column as desired\n",
    "\n",
    "def Change_Data_Type(desired_type, dataframe, columns_list=[]):\n",
    "    for column in columns_list:\n",
    "        dataframe[column]= dataframe[column].astype(desired_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5c3cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a class which compiles functions for Exploratory Data Analysis Steps which are repeated everytime\n",
    "\n",
    "class EDA():\n",
    "    \n",
    "    def __init__(self, dataframe):\n",
    "        self.dataframe = dataframe\n",
    "    \n",
    "    # Function to check number of missing values in a dataframe\n",
    "\n",
    "    def Percent_Missing(self):\n",
    "        missing_count = self.dataframe.isnull().sum()\n",
    "        percent_missing = self.dataframe.isnull().sum() * 100 / len(self.dataframe)\n",
    "        missing_value_df = pd.DataFrame({'column_name': self.dataframe.columns,\n",
    "                                         'missing_count': missing_count,\n",
    "                                         'percent_missing': percent_missing})\n",
    "        print(missing_value_df)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Function to give box plots and kde plots of int and float data (numeric data) and countplot of categorical data\n",
    "    def VisualizeDistributions(self):\n",
    "        for column in list(self.dataframe.columns):\n",
    "            try:\n",
    "                # If the data type of the variable is object, the loop will print the result\n",
    "\n",
    "                if self.dataframe[column].dtype != 'O':\n",
    "                    plt.title(f'Box Plot of {column} Variable')\n",
    "                    sns.boxplot(x=f'{column}', data=self.dataframe)\n",
    "                    plt.show()\n",
    "                    plt.title(f'KDE Plot of {column} Variable')\n",
    "                    sns.kdeplot(x=f'{column}', data=self.dataframe)\n",
    "                    plt.show()\n",
    "\n",
    "                # IF the data type is categorical, the function will create countplot showing frequency disribution\n",
    "                else:\n",
    "                    plt.title(f'Count Plot of {column} Variable')\n",
    "                    sns.countplot(x=f'{column}', data=self.dataframe)\n",
    "                    plt.show()\n",
    "            except:\n",
    "                print(f'**Value error at variable {column}**')\n",
    "                \n",
    "    # Function to remove outliers and mark the outlier values as null values which can be dropped later on\n",
    "    def RemoveOutliers(self, dataframe):\n",
    "            for x in dataframe.columns:\n",
    "                if dataframe[x].dtype != 'O':\n",
    "                    q75,q25 = np.percentile(dataframe.loc[:,x],[75,25])\n",
    "                    intr_qr = q75-q25\n",
    "\n",
    "                    max = q75+(1.5*intr_qr)\n",
    "                    min = q25-(1.5*intr_qr)\n",
    "\n",
    "                    dataframe.loc[dataframe[x] < min,x] = np.nan\n",
    "                    dataframe.loc[dataframe[x] > max,x] = np.nan\n",
    "            return dataframe\n",
    "    \n",
    "    # Function which will get us number of unique values in categorical variables\n",
    "    def Cardinality(self): \n",
    "            for column in list(self.dataframe.columns):\n",
    "                try:\n",
    "                    # If the data type of the variable is object, the loop will print the result\n",
    "                    if self.dataframe[column].dtype == 'O':\n",
    "                        print(f'Cardinality of {column} variable >> {self.dataframe[column].nunique()}')\n",
    "                \n",
    "                except:\n",
    "                    print(f'**Value error at variable {column}**')\n",
    "    \n",
    "    # Function for Standard Scaling using Min Max Scaler\n",
    "    def StandardScaler(self, df, target_variable):\n",
    "    # Using min max scaler package of sklearn library to feature scale our data\n",
    "\n",
    "        from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "        scaler = MinMaxScaler()\n",
    "        features = df.drop(columns=target_variable)\n",
    "        scaler.fit(features)\n",
    "        feature_scaled_variables_array = scaler.transform(features)\n",
    "        return feature_scaled_variables_array\n",
    "    \n",
    "    def RemoveOutliers(self, dataframe):\n",
    "        '''Any datapoint above or below 1.5 times the Inter-Quartile range of a numeric variable will be marked as null value'''\n",
    "        for x in dataframe.columns:\n",
    "            if dataframe[x].dtype != 'O':\n",
    "                q75,q25 = np.percentile(dataframe.loc[:,x],[75,25])\n",
    "                intr_qr = q75-q25\n",
    "\n",
    "                max = q75+(1.5*intr_qr)\n",
    "                min = q25-(1.5*intr_qr)\n",
    "\n",
    "                dataframe.loc[dataframe[x] < min,x] = np.nan\n",
    "                dataframe.loc[dataframe[x] > max,x] = np.nan\n",
    "        return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d1956d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function to reduce the cardinality of the variables by defining thresholds\n",
    "# Through this function we try to capture as many values of varibles as they can fit in our proportion thresholds\n",
    "# The left out values are marked under one single value as 'All Others'\n",
    "# This is done to reduce the cardinality of the features and make ML excercise more efficient and understandable\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "def cumulatively_categorise(column,threshold=0.75,return_categories_list=True):\n",
    "  #Find the threshold value using the percentage and number of instances in the column\n",
    "  threshold_value=int(threshold*len(column))\n",
    "  #Initialise an empty list for our new minimised categories\n",
    "  categories_list=[]\n",
    "  #Initialise a variable to calculate the sum of frequencies\n",
    "  s=0\n",
    "  #Create a counter dictionary of the form unique_value: frequency\n",
    "  counts=Counter(column)\n",
    "\n",
    "  #Loop through the category name and its corresponding frequency after sorting the categories by descending order of frequency\n",
    "  for i,j in counts.most_common():\n",
    "    #Add the frequency to the global sum\n",
    "    s+=dict(counts)[i]\n",
    "    #Append the category name to the list\n",
    "    categories_list.append(i)\n",
    "    #Check if the global sum has reached the threshold value, if so break the loop\n",
    "    if s>=threshold_value:\n",
    "      break\n",
    "  #Append the category Other to the list\n",
    "  categories_list.append('Other')\n",
    "\n",
    "  #Replace all instances not in our new categories by Other  \n",
    "  new_column=column.apply(lambda x: x if x in categories_list else 'All Others')\n",
    "\n",
    "  #Return transformed column and unique values if return_categories=True\n",
    "  if(return_categories_list):\n",
    "    return new_column,categories_list\n",
    "  #Return only the transformed column if return_categories=False\n",
    "  else:\n",
    "    return new_column\n",
    "\n",
    "# Code Credits: https://towardsdatascience.com/dealing-with-features-that-have-high-cardinality-1c9212d7ff1b"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
